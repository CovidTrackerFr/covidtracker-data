{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLICENSE MIT\\n2021\\nGuillaume Rozier\\nWebsite : http://www.covidtracker.fr\\nMail : guillaume.rozier@telecomnancy.net\\n\\nREADME:\\nThis file contains scripts that download data from data.gouv.fr and then process it to build many graphes.\\nI'm currently cleaning the code, please ask me if something is not clear enough.\\n\\nThe charts are exported to 'charts/images/france'.\\nData is download to/imported from 'data/france'.\\nRequirements: please see the imports below (use pip3 to install them).\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LICENSE MIT\n",
    "2021\n",
    "Guillaume Rozier\n",
    "Website : http://www.covidtracker.fr\n",
    "Mail : guillaume.rozier@telecomnancy.net\n",
    "\n",
    "README:\n",
    "This file contains scripts that download data from data.gouv.fr and then process it to build many graphes.\n",
    "I'm currently cleaning the code, please ask me if something is not clear enough.\n",
    "\n",
    "The charts are exported to 'charts/images/france'.\n",
    "Data is download to/imported from 'data/france'.\n",
    "Requirements: please see the imports below (use pip3 to install them).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import france_data_management as data\n",
    "import math\n",
    "\n",
    "show_charts = False\n",
    "PATH_STATS = \"../../data/france/stats/\"\n",
    "PATH = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions_meta = pd.read_csv(PATH+\"data/france/population_grandes_regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.download_data_obepine()\n",
    "#df_obepine = data.import_data_obepine()\n",
    "#df_obepine_france = df_obepine.groupby(\"Date\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:11,  2.65it/s]                      \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "36it [00:30,  2.65it/s]\n",
      " 38%|███▊      | 3/8 [00:18<00:31,  6.33s/it]\u001b[A/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:22<00:09,  4.76s/it]\u001b[A\n",
      "10it [00:22,  3.35s/it]                      \u001b[A\n",
      "21it [00:29,  2.52s/it]\u001b[A\n",
      "28it [03:53, 10.54s/it]\u001b[A\n",
      "36it [03:53,  7.39s/it]\u001b[A/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data.download_data()\n",
    "df, df_confirmed, dates, df_new, df_tests, df_deconf, df_sursaud, df_incid, df_tests_viros = data.import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.download_data_vue_ensemble()\n",
    "df_vue_ensemble = data.import_data_vue_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vacsi_a = data.import_data_vacsi_a_fra()\n",
    "#df_vacsi_a_reg = data.import_data_vacsi_a_reg()\n",
    "#df_vacsi_a_dep = data.import_data_vacsi_a_dep()\n",
    "\n",
    "df_vacsi = data.import_data_vacsi_fra() #df_vacsi_a.groupby(\"jour\").sum().reset_index()\n",
    "df_vacsi_reg = data.import_data_vacsi_reg() #df_vacsi_a_reg.groupby([\"jour\", \"reg\"]).sum().reset_index()\n",
    "df_vacsi_reg = df_vacsi_reg.merge(df_regions_meta, left_on=\"reg\", right_on=\"code\").rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)\n",
    "\n",
    "df_vacsi_dep = data.import_data_vacsi_dep().rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)\n",
    "#df_vacsi_a_dep.groupby([\"jour\", \"dep\"]).sum().reset_index().rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metro = data.import_data_metropoles()\n",
    "df_metro[\"jour\"] = df_metro[\"sg\"].map(lambda x: x[11:])\n",
    "\n",
    "df_metro_65 = df_metro[df_metro[\"cl_age65\"] == 65]\n",
    "df_metro_0 = df_metro[df_metro[\"cl_age65\"] == 0]\n",
    "metropoles = list(dict.fromkeys(list(df_metro['Metropole'].dropna().values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_viros_enrichi = data.import_data_tests_viros()\n",
    "df_tests_viros_enrichi = df_tests_viros_enrichi.drop(\"regionName_y\", axis=1).rename({\"regionName_x\": \"regionName\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incid_clage = df_incid.copy()\n",
    "\n",
    "df_incid_fra_clage = data.import_data_tests_sexe()\n",
    "df_incid_fra = df_incid_fra_clage[df_incid_fra_clage[\"cl_age90\"]==0]\n",
    "df_france = df.groupby([\"jour\"]).sum().reset_index()\n",
    "df_incid = df_incid[df_incid.cl_age90 == 0]\n",
    "\n",
    "df_sursaud_france = df_sursaud.groupby([\"date_de_passage\"]).sum().reset_index()\n",
    "df_sursaud_regions = df_sursaud.groupby([\"date_de_passage\", \"regionName\"]).sum().reset_index()\n",
    "\n",
    "df_new_france = df_new.groupby([\"jour\"]).sum().reset_index()\n",
    "df_new_regions = df_new.groupby([\"jour\", \"regionName\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incid_clage_regions = df_incid_clage.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_viros_regions = df_tests_viros_enrichi.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()\n",
    "df_tests_viros_france = df_tests_viros_enrichi.groupby([\"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_clage = data.import_data_hosp_clage()\n",
    "df_hosp_clage_france = df_hosp_clage.groupby([\"jour\", \"cl_age90\"]).sum().reset_index()\n",
    "df_hosp_clage_regions = df_hosp_clage.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "departements = list(dict.fromkeys(list(df_incid['dep'].values))) \n",
    "regions = list(dict.fromkeys(list(df_incid['regionName'].dropna().values))) \n",
    "clage_list = list(dict.fromkeys(list(df_incid_fra_clage['cl_age90'].dropna().values))) \n",
    "\n",
    "df_regions = df.groupby([\"jour\", \"regionName\"]).sum().reset_index()\n",
    "df_incid_regions = df_incid.groupby([\"jour\", \"regionName\"]).sum().reset_index()\n",
    "\n",
    "\n",
    "zone_a = [\"zone_a\", \"01\", \"03\", \"07\", \"15\", \"16\", \"17\", \"19\", \"21\", \"23\", \"24\", \"25\", \"26\", \"33\", \"38\", \"39\", \"40\", \"42\", \"43\", \"47\", \"58\", \"63\", \"64\", \"69\", \"70\", \"71\", \"73\", \"74\", \"79\", \"86\", \"90\"]\n",
    "zone_b = [\"zone_b\", \"02\", \"04\", \"05\", \"06\", \"08\", \"10\", \"13\", \"14\", \"18\", \"22\", \"27\", \"28\", \"29\", \"35\", \"36\", \"37\", \"41\", \"44\", \"45\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"59\", \"60\", \"61\", \"62\", \"67\", \"68\", \"72\", \"76\", \"80\", \"83\", \"84\", \"85\", \"88\"]\n",
    "zone_c = [\"zone_c\", \"09\", \"11\", \"12\", \"30\", \"31\", \"32\", \"34\", \"46\", \"48\", \"65\", \"66\", \"75\", \"77\", \"78\", \"81\", \"82\", \"91\", \"92\", \"93\", \"94\", \"95\"]\n",
    "\n",
    "confines_mars_2021 = [\"confines_mars_2021\", \"02\", \"06\", \"27\", \"59\", \"60\", \"62\", \"75\", \"76\", \"77\", \"78\", \"80\", \"91\", \"92\", \"93\", \"94\", \"95\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_incid=pd.DataFrame(), data_hosp=pd.DataFrame(), data_sursaud=pd.DataFrame(), data_new=pd.DataFrame(), data_vue_ensemble=pd.DataFrame(), data_metropole=pd.DataFrame(), data_vacsi=pd.DataFrame(), data_obepine=pd.DataFrame(), mode=\"\", export_jour=False):## Incidence\n",
    "        \n",
    "    dict_data = {}\n",
    "    \n",
    "    if export_jour:\n",
    "        dict_data[\"jour_incid\"] = list(data_incid.jour)\n",
    "        dict_data[\"jour_hosp\"] = list(data_hosp.jour)\n",
    "        dict_data[\"jour_new\"] = list(data_new.jour)\n",
    "        dict_data[\"jour_sursaud\"] = list(data_sursaud.date_de_passage)\n",
    "        dict_data[\"jour_metropoles\"] = list(data_metropole.jour.unique())\n",
    "        dict_data[\"jour_vacsi\"] = list(data_vacsi.jour)\n",
    "        dict_data[\"jour_obepine\"] = \"\"#list(data_obepine.Date)\n",
    "        \n",
    "    if(len(data_vacsi)>0):\n",
    "        n_cum_dose1 = data_vacsi[\"n_cum_dose1\"].fillna(0)\n",
    "        dict_data[\"n_cum_dose1\"] = {\"jour_nom\": \"jour_vacsi\", \"valeur\": list(n_cum_dose1)}\n",
    "        \n",
    "        n_dose1 = data_vacsi[\"n_dose1\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"n_dose1\"] = {\"jour_nom\": \"jour_vacsi\", \"valeur\": list(n_dose1)}\n",
    "    \n",
    "    if len(data_vue_ensemble)>0:\n",
    "        dict_data[\"jour_ehpad\"] = list(data_vue_ensemble.date)\n",
    "        deces_ehpad = data_vue_ensemble[\"total_deces_ehpad\"].diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"deces_ehpad\"] = {\"jour_nom\": \"jour_ehpad\", \"valeur\": list(round(deces_ehpad,2))}\n",
    "        \n",
    "        cas_spf = data_vue_ensemble.total_cas_confirmes.diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"cas_spf\"] = {\"jour_nom\": \"jour_ehpad\", \"valeur\": list(round(cas_spf, 2))}\n",
    "        \n",
    "    if len(data_obepine)>0:\n",
    "        indicateur_obepine = data_obepine.Indicateur.fillna(0)\n",
    "        \n",
    "        dict_data[\"obepine\"] = {\"jour_nom\": \"jour_obepine\", \"jours\":list(data_obepine.Date), \"valeur\": list(round(indicateur_obepine, 2))}\n",
    "        \n",
    "    if len(data_incid)>0:\n",
    "        taux_incidence = data_incid[\"P\"].rolling(window=7).sum().fillna(0) * 100000 / int(data_incid[\"pop\"].values[0])\n",
    "        dict_data[\"incidence\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_incidence,2))}\n",
    "\n",
    "        taux_positivite = (data_incid[\"P\"] / data_incid[\"T\"] * 100).rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"taux_positivite\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "        \n",
    "        taux_positivite = (data_incid[\"P\"].rolling(window=7).mean() / data_incid[\"T\"].rolling(window=7).mean() * 100).fillna(0)\n",
    "        dict_data[\"taux_positivite_rolling_before\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "    \n",
    "        cas = data_incid[\"P\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"cas\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(cas,2))}\n",
    "    \n",
    "        tests = data_incid[\"T\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"tests\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(tests,2))}\n",
    "        \n",
    "    if (len(data_metropole)>0) & (mode==\"metropoles\"):\n",
    "        taux_incidence = data_metropole[\"ti\"].fillna(0)\n",
    "        dict_data[\"incidence\"] = {\"jour_nom\": \"jour_metropoles\", \"valeur\": list(round(taux_incidence, 2))}\n",
    "        \n",
    "    if len(data_hosp)>0:\n",
    "        hospitalisations = data_hosp.hosp.fillna(0)\n",
    "        dict_data[\"hospitalisations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(hospitalisations)}\n",
    "\n",
    "        reanimations = data_hosp.rea.fillna(0)\n",
    "        dict_data[\"reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(reanimations)}\n",
    "        \n",
    "        saturation_rea = round(data_hosp[\"rea\"]/data_hosp[\"LITS\"].fillna(0)*100, 2)\n",
    "        dict_data[\"saturation_reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(saturation_rea)}\n",
    "    \n",
    "    if len(data_new)>0:\n",
    "        incid_hospitalisations = data_new.incid_hosp.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"incid_hospitalisations\"] = {\"jour_nom\": \"jour_new\", \"valeur\": list(round(incid_hospitalisations, 2))}\n",
    "\n",
    "        incid_reanimations = data_new.incid_rea.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"incid_reanimations\"] = {\"jour_nom\": \"jour_new\", \"valeur\": list(round(incid_reanimations,2))}\n",
    "    \n",
    "    if len(data_sursaud)>0:\n",
    "        nbre_acte_corona = data_sursaud.nbre_acte_corona.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"nbre_acte_corona\"] = {\"jour_nom\": \"jour_sursaud\", \"valeur\": list(round(nbre_acte_corona, 2))}\n",
    "\n",
    "        nbre_pass_corona = data_sursaud.nbre_pass_corona.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"nbre_pass_corona\"] = {\"jour_nom\": \"jour_sursaud\", \"valeur\": list(round(nbre_pass_corona, 2))}\n",
    "    \n",
    "    if len(data_hosp)>0:\n",
    "        deces_hospitaliers = data_hosp.dc.diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"deces_hospitaliers\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(round(deces_hospitaliers,2))}\n",
    "    \n",
    "    if len(data_incid)>0:\n",
    "        population = data_incid[\"pop\"].values[0]\n",
    "        dict_data[\"population\"] = population\n",
    "\n",
    "    return dict_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_age(data_incid, data_hosp, export_jour=False):## Incidence\n",
    "    clage_tranches = [[0], [9, 19], [29, 39], [49, 59], [69, 79], [89, 90]]\n",
    "    clage_noms = [\"tous\", \"19\", \"39\", \"59\", \"79\", \"90\"]\n",
    "    clage_noms_disp = [\"Tous âges\", \"0 à 19 ans\", \"20 à 39 ans\", \"40 à 59 ans\", \"60 à 79 ans\", \"Plus de 80 ans\"]\n",
    "    \n",
    "    dict_data = {}\n",
    "    \n",
    "    for (idx, clage) in enumerate(clage_tranches):\n",
    "        clage_nom = clage_noms[idx]\n",
    "        \n",
    "        data_incid_clage = data_incid[data_incid.cl_age90.isin(clage)].groupby(\"jour\").sum().reset_index()\n",
    "\n",
    "        dict_data[clage_nom] = {}\n",
    "\n",
    "        taux_incidence = data_incid_clage[\"P\"].rolling(window=7).sum().fillna(0) * 100000 / data_incid_clage[\"pop\"].values[0]\n",
    "        dict_data[clage_nom][\"incidence\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_incidence,2))}\n",
    "\n",
    "        taux_positivite = (data_incid_clage[\"P\"] / data_incid_clage[\"T\"] * 100).rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"taux_positivite\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "\n",
    "        cas = data_incid_clage[\"P\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"cas\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(cas,2))}\n",
    "\n",
    "        tests = data_incid_clage[\"T\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"tests\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(tests,2))}\n",
    "        \n",
    "        population = data_incid_clage[\"pop\"].values[0]\n",
    "        dict_data[clage_nom][\"population\"] = population\n",
    "        \n",
    "        if (len(data_hosp)):\n",
    "            \n",
    "            data_hosp_clage = data_hosp[data_hosp.cl_age90.isin(clage)].groupby(\"jour\").sum().reset_index()\n",
    "            hospitalisations = data_hosp_clage.hosp.fillna(0)\n",
    "            dict_data[clage_nom][\"hospitalisations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(hospitalisations)}\n",
    "\n",
    "            reanimations = data_hosp_clage.rea.fillna(0)\n",
    "            dict_data[clage_nom][\"reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(reanimations)}\n",
    "\n",
    "            deces_hospitaliers = data_hosp_clage.dc.diff().rolling(window=7).mean().fillna(0)\n",
    "            dict_data[clage_nom][\"deces_hospitaliers\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(round(deces_hospitaliers,2))}\n",
    "        \n",
    "    if export_jour:\n",
    "            dict_data[\"jour_incid\"] = list(data_incid.jour.unique())\n",
    "            dict_data[\"jour_hosp\"] = list(data_hosp.jour.unique())\n",
    "            dict_data[\"tranches\"] = clage_tranches\n",
    "            dict_data[\"tranches_noms\"] = clage_noms\n",
    "            dict_data[\"tranches_noms_affichage\"] = clage_noms_disp\n",
    "\n",
    "    return dict_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data, suffix=\"\"):\n",
    "    with open(PATH_STATS + 'dataexplorer{}.json'.format(suffix), 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataexplorer():\n",
    "    dict_data = {}\n",
    "    \n",
    "    dict_data[\"regions\"] = sorted(regions)\n",
    "    dict_data[\"metropoles\"] = sorted(metropoles)\n",
    "    dict_data[\"departements\"] = departements\n",
    "    dict_data[\"france\"] = generate_data(df_incid_fra, df_france, df_sursaud_france, df_new_france, df_vue_ensemble, data_metropole=df_metro_0, data_vacsi=df_vacsi, data_obepine=pd.DataFrame(), mode=\"france\", export_jour=True)\n",
    "    \n",
    "    noms_departements={}\n",
    "    \n",
    "    for reg in regions:\n",
    "        \n",
    "        dict_data[reg] = generate_data(df_incid_regions[df_incid_regions.regionName==reg], \\\n",
    "                                       df_regions[df_regions.regionName==reg],\\\n",
    "                                       df_sursaud_regions[df_sursaud_regions.regionName==reg],\n",
    "                                       df_new_regions[df_new_regions.regionName==reg],\n",
    "                                       data_vacsi=df_vacsi_reg[df_vacsi_reg.regionName==reg],\\\n",
    "                                       data_obepine=None, #df_obepine[df_obepine.regionName==reg]\n",
    "                                      )\n",
    "        #print(df_vacsi_reg[df_vacsi_reg.regionName==reg])\n",
    "    \n",
    "    for dep in departements:\n",
    "        df_incid_dep = df_incid[df_incid.dep==dep]\n",
    "        dict_data[dep] = generate_data(df_incid_dep, df[df.dep==dep], df_sursaud[df_sursaud.dep==dep], df_new[df_new.dep==dep], data_vacsi=df_vacsi_dep[df_vacsi_dep.dep==dep])\n",
    "        \n",
    "        noms_departements[dep] = df_incid_dep[\"departmentName\"].values[0]\n",
    "    dict_data[\"departements_noms\"] = noms_departements\n",
    "    \n",
    "    for zone in [zone_a, zone_b, zone_c]:\n",
    "        df_incid_zone = df_incid[df_incid.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_zone = df[df.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_sursaud_zone = df_sursaud[df_sursaud.dep.isin(zone)].groupby(\"date_de_passage\").sum().reset_index()\n",
    "        df_new_zone = df_new[df_new.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_vacsi_zone = df_vacsi_dep[df_vacsi_dep.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        \n",
    "        dict_data[zone[0]] = generate_data(df_incid_zone, df_zone, df_sursaud_zone, df_new_zone, data_vacsi=df_vacsi_zone)\n",
    "    \n",
    "    # Confinés mars 2021\n",
    "    df_incid_zone = df_incid[df_incid.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_zone = df[df.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_sursaud_zone = df_sursaud[df_sursaud.dep.isin(confines_mars_2021)].groupby(\"date_de_passage\").sum().reset_index()\n",
    "    df_new_zone = df_new[df_new.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_vacsi_zone = df_vacsi_dep[df_vacsi_dep.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    \n",
    "    dict_data[\"confines_mars_2021\"] = generate_data(df_incid_zone, df_zone, df_sursaud_zone, df_new_zone, data_vacsi=df_vacsi_zone)\n",
    "        \n",
    "    for metropole in metropoles:\n",
    "        print(metropole)\n",
    "        dict_data[metropole] = generate_data(data_metropole=df_metro_0[df_metro_0.Metropole == metropole], mode=\"metropoles\")\n",
    "        #print(dict_data[metropole])\n",
    "        \n",
    "    dict_data[\"zones_vacances\"] = [\"zone_a\", \"zone_b\", \"zone_c\"]\n",
    "    \n",
    "    export_data(dict_data, suffix=\"_compr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dataexplorer_age():\n",
    "    dict_data = {}\n",
    "    regions_tests_viros = list(dict.fromkeys(list(df_tests_viros_enrichi['regionName'].dropna().values))) \n",
    "    departements_tests_viros = list(dict.fromkeys(list(df_tests_viros_enrichi['dep'].dropna().values))) \n",
    "    dict_data[\"regions\"] = sorted(regions_tests_viros)\n",
    "    dict_data[\"departements\"] = sorted(departements_tests_viros)\n",
    "    \n",
    "    dict_data[\"france\"] = generate_data_age(df_tests_viros_france, df_hosp_clage_france, export_jour=True)\n",
    "    \n",
    "    for reg in regions_tests_viros:\n",
    "        dict_data[reg] = generate_data_age(df_tests_viros_regions[df_tests_viros_regions.regionName == reg],\\\n",
    "                                           df_hosp_clage_regions[df_hosp_clage_regions.regionName == reg])\n",
    "    noms_departements={}\n",
    "    for dep in departements_tests_viros:\n",
    "        df_tests_viros_enrichi_temp = df_tests_viros_enrichi[df_tests_viros_enrichi.dep == dep]\n",
    "        dict_data[dep] = generate_data_age(df_tests_viros_enrichi_temp,\\\n",
    "                                           pd.DataFrame())\n",
    "        \n",
    "        nom_dep = df_tests_viros_enrichi_temp[\"departmentName\"].values[0]\n",
    "        \n",
    "        if(type(nom_dep) is float): #Pas de nom, nom_dep == NaN\n",
    "            #print(dep)\n",
    "            nom_dep = \"--\"\n",
    "        \n",
    "        noms_departements[dep] = nom_dep\n",
    "        \n",
    "    dict_data[\"departements_noms\"] = noms_departements\n",
    "    \n",
    "    export_data(dict_data, suffix=\"_compr_age\")\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           0.0\n",
      "1           0.0\n",
      "2           0.0\n",
      "3           0.0\n",
      "4           0.0\n",
      "         ...   \n",
      "730    231078.0\n",
      "731    224570.0\n",
      "732    223168.0\n",
      "733    208802.0\n",
      "734    199775.0\n",
      "Name: P, Length: 735, dtype: float64\n",
      "67114992\n",
      "Rouen\n",
      "Nice\n",
      "Metz\n",
      "Grenoble\n",
      "Lyon\n",
      "Paris\n",
      "Marseille\n",
      "Dijon\n",
      "Brest\n",
      "Toulouse\n",
      "Bordeaux\n",
      "Montpellier\n",
      "Rennes\n",
      "Tours\n",
      "Saint Etienne\n",
      "Nantes\n",
      "Orléans\n",
      "Nancy\n",
      "Lille\n",
      "Clermont-Auvergne\n",
      "Strasbourg\n",
      "Toulon\n"
     ]
    }
   ],
   "source": [
    "dataexplorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data = dataexplorer_age()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
