{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nLICENSE MIT\\n2021\\nGuillaume Rozier\\nWebsite : http://www.covidtracker.fr\\nMail : guillaume.rozier@telecomnancy.net\\n\\nREADME:\\nThis file contains scripts that download data from data.gouv.fr and then process it to build many graphes.\\nI'm currently cleaning the code, please ask me if something is not clear enough.\\n\\nThe charts are exported to 'charts/images/france'.\\nData is download to/imported from 'data/france'.\\nRequirements: please see the imports below (use pip3 to install them).\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LICENSE MIT\n",
    "2021\n",
    "Guillaume Rozier\n",
    "Website : http://www.covidtracker.fr\n",
    "Mail : guillaume.rozier@telecomnancy.net\n",
    "\n",
    "README:\n",
    "This file contains scripts that download data from data.gouv.fr and then process it to build many graphes.\n",
    "I'm currently cleaning the code, please ask me if something is not clear enough.\n",
    "\n",
    "The charts are exported to 'charts/images/france'.\n",
    "Data is download to/imported from 'data/france'.\n",
    "Requirements: please see the imports below (use pip3 to install them).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import france_data_management as data\n",
    "import math\n",
    "\n",
    "show_charts = False\n",
    "PATH_STATS = \"../../data/france/stats/\"\n",
    "PATH = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions_meta = pd.read_csv(PATH+\"data/france/population_grandes_regions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guillaumerozier/Documents/Education/Covid-19_new/covid-19/src/france/france_data_management.py:68: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(PATH + 'data/france/donnees_obepine_regions.csv', sep=None)\n"
     ]
    }
   ],
   "source": [
    "data.download_data_obepine()\n",
    "df_obepine = data.import_data_obepine()\n",
    "df_obepine_france = df_obepine.groupby(\"Date\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [00:07,  4.88it/s]                      \n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "36it [03:03,  5.59s/it]                      /Users/guillaumerozier/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data.download_data()\n",
    "df, df_confirmed, dates, df_new, df_tests, df_deconf, df_sursaud, df_incid, df_tests_viros = data.import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.download_data_vue_ensemble()\n",
    "df_vue_ensemble = data.import_data_vue_ensemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_vacsi_a = data.import_data_vacsi_a_fra()\n",
    "#df_vacsi_a_reg = data.import_data_vacsi_a_reg()\n",
    "#df_vacsi_a_dep = data.import_data_vacsi_a_dep()\n",
    "\n",
    "df_vacsi = data.import_data_vacsi_fra() #df_vacsi_a.groupby(\"jour\").sum().reset_index()\n",
    "df_vacsi_reg = data.import_data_vacsi_reg() #df_vacsi_a_reg.groupby([\"jour\", \"reg\"]).sum().reset_index()\n",
    "df_vacsi_reg = df_vacsi_reg.merge(df_regions_meta, left_on=\"reg\", right_on=\"code\").rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)\n",
    "\n",
    "df_vacsi_dep = data.import_data_vacsi_dep().rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)\n",
    "#df_vacsi_a_dep.groupby([\"jour\", \"dep\"]).sum().reset_index().rename({\"n_tot_dose1\": \"n_cum_dose1\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metro = data.import_data_metropoles()\n",
    "df_metro[\"jour\"] = df_metro[\"semaine_glissante\"].map(lambda x: x[11:])\n",
    "\n",
    "df_metro_65 = df_metro[df_metro[\"clage_65\"] == 65]\n",
    "df_metro_0 = df_metro[df_metro[\"clage_65\"] == 0]\n",
    "metropoles = list(dict.fromkeys(list(df_metro['Metropole'].dropna().values))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_viros_enrichi = data.import_data_tests_viros()\n",
    "df_tests_viros_enrichi = df_tests_viros_enrichi.drop(\"regionName_y\", axis=1).rename({\"regionName_x\": \"regionName\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incid_clage = df_incid.copy()\n",
    "\n",
    "df_incid_fra_clage = data.import_data_tests_sexe()\n",
    "df_incid_fra = df_incid_fra_clage[df_incid_fra_clage[\"cl_age90\"]==0]\n",
    "df_france = df.groupby([\"jour\"]).sum().reset_index()\n",
    "df_incid = df_incid[df_incid.cl_age90 == 0]\n",
    "\n",
    "df_sursaud_france = df_sursaud.groupby([\"date_de_passage\"]).sum().reset_index()\n",
    "df_sursaud_regions = df_sursaud.groupby([\"date_de_passage\", \"regionName\"]).sum().reset_index()\n",
    "\n",
    "df_new_france = df_new.groupby([\"jour\"]).sum().reset_index()\n",
    "df_new_regions = df_new.groupby([\"jour\", \"regionName\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_incid_clage_regions = df_incid_clage.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tests_viros_regions = df_tests_viros_enrichi.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()\n",
    "df_tests_viros_france = df_tests_viros_enrichi.groupby([\"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hosp_clage = data.import_data_hosp_clage()\n",
    "df_hosp_clage_france = df_hosp_clage.groupby([\"jour\", \"cl_age90\"]).sum().reset_index()\n",
    "df_hosp_clage_regions = df_hosp_clage.groupby([\"regionName\", \"jour\", \"cl_age90\"]).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "departements = list(dict.fromkeys(list(df_incid['dep'].values))) \n",
    "regions = list(dict.fromkeys(list(df_incid['regionName'].dropna().values))) \n",
    "clage_list = list(dict.fromkeys(list(df_incid_fra_clage['cl_age90'].dropna().values))) \n",
    "\n",
    "df_regions = df.groupby([\"jour\", \"regionName\"]).sum().reset_index()\n",
    "df_incid_regions = df_incid.groupby([\"jour\", \"regionName\"]).sum().reset_index()\n",
    "\n",
    "\n",
    "zone_a = [\"zone_a\", \"01\", \"03\", \"07\", \"15\", \"16\", \"17\", \"19\", \"21\", \"23\", \"24\", \"25\", \"26\", \"33\", \"38\", \"39\", \"40\", \"42\", \"43\", \"47\", \"58\", \"63\", \"64\", \"69\", \"70\", \"71\", \"73\", \"74\", \"79\", \"86\", \"90\"]\n",
    "zone_b = [\"zone_b\", \"02\", \"04\", \"05\", \"06\", \"08\", \"10\", \"13\", \"14\", \"18\", \"22\", \"27\", \"28\", \"29\", \"35\", \"36\", \"37\", \"41\", \"44\", \"45\", \"49\", \"50\", \"51\", \"52\", \"53\", \"54\", \"55\", \"56\", \"57\", \"59\", \"60\", \"61\", \"62\", \"67\", \"68\", \"72\", \"76\", \"80\", \"83\", \"84\", \"85\", \"88\"]\n",
    "zone_c = [\"zone_c\", \"09\", \"11\", \"12\", \"30\", \"31\", \"32\", \"34\", \"46\", \"48\", \"65\", \"66\", \"75\", \"77\", \"78\", \"81\", \"82\", \"91\", \"92\", \"93\", \"94\", \"95\"]\n",
    "\n",
    "confines_mars_2021 = [\"confines_mars_2021\", \"02\", \"06\", \"27\", \"59\", \"60\", \"62\", \"75\", \"76\", \"77\", \"78\", \"80\", \"91\", \"92\", \"93\", \"94\", \"95\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(data_incid=pd.DataFrame(), data_hosp=pd.DataFrame(), data_sursaud=pd.DataFrame(), data_new=pd.DataFrame(), data_vue_ensemble=pd.DataFrame(), data_metropole=pd.DataFrame(), data_vacsi=pd.DataFrame(), data_obepine=pd.DataFrame(), mode=\"\", export_jour=False):## Incidence\n",
    "        \n",
    "    dict_data = {}\n",
    "    \n",
    "    if export_jour:\n",
    "        dict_data[\"jour_incid\"] = list(data_incid.jour)\n",
    "        dict_data[\"jour_hosp\"] = list(data_hosp.jour)\n",
    "        dict_data[\"jour_new\"] = list(data_new.jour)\n",
    "        dict_data[\"jour_sursaud\"] = list(data_sursaud.date_de_passage)\n",
    "        dict_data[\"jour_metropoles\"] = list(data_metropole.jour.unique())\n",
    "        dict_data[\"jour_vacsi\"] = list(data_vacsi.jour)\n",
    "        dict_data[\"jour_obepine\"] = list(data_obepine.Date)\n",
    "        \n",
    "    if(len(data_vacsi)>0):\n",
    "        n_cum_dose1 = data_vacsi[\"n_cum_dose1\"].fillna(0)\n",
    "        dict_data[\"n_cum_dose1\"] = {\"jour_nom\": \"jour_vacsi\", \"valeur\": list(n_cum_dose1)}\n",
    "        \n",
    "        n_dose1 = data_vacsi[\"n_dose1\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"n_dose1\"] = {\"jour_nom\": \"jour_vacsi\", \"valeur\": list(n_dose1)}\n",
    "    \n",
    "    if len(data_vue_ensemble)>0:\n",
    "        dict_data[\"jour_ehpad\"] = list(data_vue_ensemble.date)\n",
    "        deces_ehpad = data_vue_ensemble[\"total_deces_ehpad\"].diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"deces_ehpad\"] = {\"jour_nom\": \"jour_ehpad\", \"valeur\": list(round(deces_ehpad,2))}\n",
    "        \n",
    "        cas_spf = data_vue_ensemble.total_cas_confirmes.diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"cas_spf\"] = {\"jour_nom\": \"jour_ehpad\", \"valeur\": list(round(cas_spf, 2))}\n",
    "        \n",
    "    if len(data_obepine)>0:\n",
    "        indicateur_obepine = data_obepine.Indicateur.fillna(0)\n",
    "        \n",
    "        dict_data[\"obepine\"] = {\"jour_nom\": \"jour_obepine\", \"jours\":list(data_obepine.Date), \"valeur\": list(round(indicateur_obepine, 2))}\n",
    "        \n",
    "    if len(data_incid)>0:\n",
    "        taux_incidence = data_incid[\"P\"].rolling(window=7).sum().fillna(0) * 100000 / data_incid[\"pop\"].values[0]\n",
    "        dict_data[\"incidence\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_incidence,2))}\n",
    "\n",
    "        taux_positivite = (data_incid[\"P\"] / data_incid[\"T\"] * 100).rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"taux_positivite\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "        \n",
    "        taux_positivite = (data_incid[\"P\"].rolling(window=7).mean() / data_incid[\"T\"].rolling(window=7).mean() * 100).fillna(0)\n",
    "        dict_data[\"taux_positivite_rolling_before\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "    \n",
    "        cas = data_incid[\"P\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"cas\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(cas,2))}\n",
    "    \n",
    "        tests = data_incid[\"T\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"tests\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(tests,2))}\n",
    "        \n",
    "    if (len(data_metropole)>0) & (mode==\"metropoles\"):\n",
    "        taux_incidence = data_metropole[\"ti\"].fillna(0)\n",
    "        dict_data[\"incidence\"] = {\"jour_nom\": \"jour_metropoles\", \"valeur\": list(round(taux_incidence, 2))}\n",
    "        \n",
    "    if len(data_hosp)>0:\n",
    "        hospitalisations = data_hosp.hosp.fillna(0)\n",
    "        dict_data[\"hospitalisations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(hospitalisations)}\n",
    "\n",
    "        reanimations = data_hosp.rea.fillna(0)\n",
    "        dict_data[\"reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(reanimations)}\n",
    "        \n",
    "        saturation_rea = round(data_hosp[\"rea\"]/data_hosp[\"LITS\"].fillna(0)*100, 2)\n",
    "        dict_data[\"saturation_reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(saturation_rea)}\n",
    "    \n",
    "    if len(data_new)>0:\n",
    "        incid_hospitalisations = data_new.incid_hosp.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"incid_hospitalisations\"] = {\"jour_nom\": \"jour_new\", \"valeur\": list(round(incid_hospitalisations, 2))}\n",
    "\n",
    "        incid_reanimations = data_new.incid_rea.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"incid_reanimations\"] = {\"jour_nom\": \"jour_new\", \"valeur\": list(round(incid_reanimations,2))}\n",
    "    \n",
    "    if len(data_sursaud)>0:\n",
    "        nbre_acte_corona = data_sursaud.nbre_acte_corona.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"nbre_acte_corona\"] = {\"jour_nom\": \"jour_sursaud\", \"valeur\": list(round(nbre_acte_corona, 2))}\n",
    "\n",
    "        nbre_pass_corona = data_sursaud.nbre_pass_corona.rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"nbre_pass_corona\"] = {\"jour_nom\": \"jour_sursaud\", \"valeur\": list(round(nbre_pass_corona, 2))}\n",
    "    \n",
    "    if len(data_hosp)>0:\n",
    "        deces_hospitaliers = data_hosp.dc.diff().rolling(window=7).mean().fillna(0)\n",
    "        dict_data[\"deces_hospitaliers\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(round(deces_hospitaliers,2))}\n",
    "    \n",
    "    if len(data_incid)>0:\n",
    "        population = data_incid[\"pop\"].values[0]\n",
    "        dict_data[\"population\"] = population\n",
    "\n",
    "    return dict_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_age(data_incid, data_hosp, export_jour=False):## Incidence\n",
    "    clage_tranches = [[0], [9, 19], [29, 39], [49, 59], [69, 79], [89, 90]]\n",
    "    clage_noms = [\"tous\", \"19\", \"39\", \"59\", \"79\", \"90\"]\n",
    "    clage_noms_disp = [\"Tous âges\", \"0 à 19 ans\", \"20 à 39 ans\", \"40 à 59 ans\", \"60 à 79 ans\", \"Plus de 80 ans\"]\n",
    "    \n",
    "    dict_data = {}\n",
    "    \n",
    "    for (idx, clage) in enumerate(clage_tranches):\n",
    "        clage_nom = clage_noms[idx]\n",
    "        \n",
    "        data_incid_clage = data_incid[data_incid.cl_age90.isin(clage)].groupby(\"jour\").sum().reset_index()\n",
    "\n",
    "        dict_data[clage_nom] = {}\n",
    "\n",
    "        taux_incidence = data_incid_clage[\"P\"].rolling(window=7).sum().fillna(0) * 100000 / data_incid_clage[\"pop\"].values[0]\n",
    "        dict_data[clage_nom][\"incidence\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_incidence,2))}\n",
    "\n",
    "        taux_positivite = (data_incid_clage[\"P\"] / data_incid_clage[\"T\"] * 100).rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"taux_positivite\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(taux_positivite,2))}\n",
    "\n",
    "        cas = data_incid_clage[\"P\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"cas\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(cas,2))}\n",
    "\n",
    "        tests = data_incid_clage[\"T\"].rolling(window=7).mean().fillna(0)\n",
    "        dict_data[clage_nom][\"tests\"] = {\"jour_nom\": \"jour_incid\", \"valeur\": list(round(tests,2))}\n",
    "        \n",
    "        population = data_incid_clage[\"pop\"].values[0]\n",
    "        dict_data[clage_nom][\"population\"] = population\n",
    "        \n",
    "        if (len(data_hosp)):\n",
    "            \n",
    "            data_hosp_clage = data_hosp[data_hosp.cl_age90.isin(clage)].groupby(\"jour\").sum().reset_index()\n",
    "            hospitalisations = data_hosp_clage.hosp.fillna(0)\n",
    "            dict_data[clage_nom][\"hospitalisations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(hospitalisations)}\n",
    "\n",
    "            reanimations = data_hosp_clage.rea.fillna(0)\n",
    "            dict_data[clage_nom][\"reanimations\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(reanimations)}\n",
    "\n",
    "            deces_hospitaliers = data_hosp_clage.dc.diff().rolling(window=7).mean().fillna(0)\n",
    "            dict_data[clage_nom][\"deces_hospitaliers\"] = {\"jour_nom\": \"jour_hosp\", \"valeur\": list(round(deces_hospitaliers,2))}\n",
    "        \n",
    "    if export_jour:\n",
    "            dict_data[\"jour_incid\"] = list(data_incid.jour.unique())\n",
    "            dict_data[\"jour_hosp\"] = list(data_hosp.jour.unique())\n",
    "            dict_data[\"tranches\"] = clage_tranches\n",
    "            dict_data[\"tranches_noms\"] = clage_noms\n",
    "            dict_data[\"tranches_noms_affichage\"] = clage_noms_disp\n",
    "\n",
    "    return dict_data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data, suffix=\"\"):\n",
    "    with open(PATH_STATS + 'dataexplorer{}.json'.format(suffix), 'w') as outfile:\n",
    "        json.dump(data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '2A',\n",
       " '2B',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '49',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '71',\n",
       " '72',\n",
       " '73',\n",
       " '74',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '80',\n",
       " '81',\n",
       " '82',\n",
       " '83',\n",
       " '84',\n",
       " '85',\n",
       " '86',\n",
       " '87',\n",
       " '88',\n",
       " '89',\n",
       " '90',\n",
       " '91',\n",
       " '92',\n",
       " '93',\n",
       " '94',\n",
       " '95',\n",
       " '971',\n",
       " '972',\n",
       " '973',\n",
       " '974',\n",
       " '975',\n",
       " '976',\n",
       " '978']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataexplorer():\n",
    "    dict_data = {}\n",
    "    \n",
    "    dict_data[\"regions\"] = sorted(regions)\n",
    "    dict_data[\"metropoles\"] = sorted(metropoles)\n",
    "    dict_data[\"departements\"] = departements\n",
    "    dict_data[\"france\"] = generate_data(df_incid_fra, df_france, df_sursaud_france, df_new_france, df_vue_ensemble, data_metropole=df_metro_0, data_vacsi=df_vacsi, data_obepine=df_obepine_france, mode=\"france\", export_jour=True)\n",
    "    \n",
    "    noms_departements={}\n",
    "    \n",
    "    for reg in regions:\n",
    "        \n",
    "        dict_data[reg] = generate_data(df_incid_regions[df_incid_regions.regionName==reg], \\\n",
    "                                       df_regions[df_regions.regionName==reg],\\\n",
    "                                       df_sursaud_regions[df_sursaud_regions.regionName==reg],\n",
    "                                       df_new_regions[df_new_regions.regionName==reg],\n",
    "                                       data_vacsi=df_vacsi_reg[df_vacsi_reg.regionName==reg],\\\n",
    "                                       data_obepine=df_obepine[df_obepine.regionName==reg]\n",
    "                                      )\n",
    "        #print(df_vacsi_reg[df_vacsi_reg.regionName==reg])\n",
    "    \n",
    "    for dep in departements:\n",
    "        df_incid_dep = df_incid[df_incid.dep==dep]\n",
    "        dict_data[dep] = generate_data(df_incid_dep, df[df.dep==dep], df_sursaud[df_sursaud.dep==dep], df_new[df_new.dep==dep], data_vacsi=df_vacsi_dep[df_vacsi_dep.dep==dep])\n",
    "        \n",
    "        noms_departements[dep] = df_incid_dep[\"departmentName\"].values[0]\n",
    "    dict_data[\"departements_noms\"] = noms_departements\n",
    "    \n",
    "    for zone in [zone_a, zone_b, zone_c]:\n",
    "        df_incid_zone = df_incid[df_incid.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_zone = df[df.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_sursaud_zone = df_sursaud[df_sursaud.dep.isin(zone)].groupby(\"date_de_passage\").sum().reset_index()\n",
    "        df_new_zone = df_new[df_new.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        df_vacsi_zone = df_vacsi_dep[df_vacsi_dep.dep.isin(zone)].groupby(\"jour\").sum().reset_index()\n",
    "        \n",
    "        dict_data[zone[0]] = generate_data(df_incid_zone, df_zone, df_sursaud_zone, df_new_zone, data_vacsi=df_vacsi_zone)\n",
    "    \n",
    "    # Confinés mars 2021\n",
    "    df_incid_zone = df_incid[df_incid.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_zone = df[df.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_sursaud_zone = df_sursaud[df_sursaud.dep.isin(confines_mars_2021)].groupby(\"date_de_passage\").sum().reset_index()\n",
    "    df_new_zone = df_new[df_new.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    df_vacsi_zone = df_vacsi_dep[df_vacsi_dep.dep.isin(confines_mars_2021)].groupby(\"jour\").sum().reset_index()\n",
    "    \n",
    "    dict_data[\"confines_mars_2021\"] = generate_data(df_incid_zone, df_zone, df_sursaud_zone, df_new_zone, data_vacsi=df_vacsi_zone)\n",
    "        \n",
    "    for metropole in metropoles:\n",
    "        print(metropole)\n",
    "        dict_data[metropole] = generate_data(data_metropole=df_metro_0[df_metro_0.Metropole == metropole], mode=\"metropoles\")\n",
    "        #print(dict_data[metropole])\n",
    "        \n",
    "    dict_data[\"zones_vacances\"] = [\"zone_a\", \"zone_b\", \"zone_c\"]\n",
    "    \n",
    "    export_data(dict_data, suffix=\"_compr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def dataexplorer_age():\n",
    "    dict_data = {}\n",
    "    regions_tests_viros = list(dict.fromkeys(list(df_tests_viros_enrichi['regionName'].dropna().values))) \n",
    "    departements_tests_viros = list(dict.fromkeys(list(df_tests_viros_enrichi['dep'].dropna().values))) \n",
    "    dict_data[\"regions\"] = sorted(regions_tests_viros)\n",
    "    dict_data[\"departements\"] = sorted(departements_tests_viros)\n",
    "    \n",
    "    dict_data[\"france\"] = generate_data_age(df_tests_viros_france, df_hosp_clage_france, export_jour=True)\n",
    "    \n",
    "    for reg in regions_tests_viros:\n",
    "        dict_data[reg] = generate_data_age(df_tests_viros_regions[df_tests_viros_regions.regionName == reg],\\\n",
    "                                           df_hosp_clage_regions[df_hosp_clage_regions.regionName == reg])\n",
    "    noms_departements={}\n",
    "    for dep in departements_tests_viros:\n",
    "        df_tests_viros_enrichi_temp = df_tests_viros_enrichi[df_tests_viros_enrichi.dep == dep]\n",
    "        dict_data[dep] = generate_data_age(df_tests_viros_enrichi_temp,\\\n",
    "                                           pd.DataFrame())\n",
    "        \n",
    "        nom_dep = df_tests_viros_enrichi_temp[\"departmentName\"].values[0]\n",
    "        \n",
    "        if(type(nom_dep) is float): #Pas de nom, nom_dep == NaN\n",
    "            #print(dep)\n",
    "            nom_dep = \"--\"\n",
    "        \n",
    "        noms_departements[dep] = nom_dep\n",
    "        \n",
    "    dict_data[\"departements_noms\"] = noms_departements\n",
    "    \n",
    "    export_data(dict_data, suffix=\"_compr_age\")\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice\n",
      "Marseille\n",
      "Dijon\n",
      "Brest\n",
      "Toulouse\n",
      "Bordeaux\n",
      "Montpellier\n",
      "Rennes\n",
      "Tours\n",
      "Grenoble\n",
      "Saint Etienne\n",
      "Nantes\n",
      "Orléans\n",
      "Nancy\n",
      "Metz\n",
      "Lille\n",
      "Clermont-Auvergne\n",
      "Strasbourg\n",
      "Lyon\n",
      "Paris\n",
      "Rouen\n",
      "Toulon\n"
     ]
    }
   ],
   "source": [
    "dataexplorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [03:20,  5.59s/it]"
     ]
    }
   ],
   "source": [
    "dict_data = dataexplorer_age()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
